import{A as n}from"./assets._uWmEoCi.js";import{b as m}from"./paths.kgC1Tti2.js";import{a as o}from"./skills.DDrQAjUr.js";const e=t=>`${m}/image/${t}`,a={ComidaDLVae:e("comida_rapida_IV_vae.png"),ComidaDLReg:e("comida_rapida_IV_reg.png"),ComidaDLRF:e("comida_rapida_IV_rf.png"),ComidaDLDLArq:e("comida_rapida_IV_dl_arq.png"),ComidaDLDLRes:e("comida_rapida_IV_dl_res.png"),ComidaDLCNNArq:e("comida_rapida_IV_cnn_arq.png"),ComidaDLCNNRes:e("comida_rapida_IV_cnn_res.png"),ComidaDLCNNVaeRes:e("comida_rapida_IV_cnn_vae_res.png"),ComidaDLCNNPred:e("comida_rapida_IV_cnn_pred.png"),ComidaSOM:e("comida_rapida_III_som.png"),ComidaPCAdia:e("comida_rapida_III_PCA_dia.png"),ComidaPCAprod:e("comida_rapida_III_PCA_producto.png"),ComidaPCAventa:e("comida_rapida_III_PCA_venta.png"),ComidaISOMAPdia:e("comida_rapida_III_ISOMAP_dia.png"),ComidaISOMAPprod:e("comida_rapida_III_ISOMAP_producto.png"),ComidaISOMAPventa:e("comida_rapida_III_ISOMAP_venta.png"),ComidaTSNEdia:e("comida_rapida_III_tSNE_dia.png"),ComidaTSNEprod:e("comida_rapida_III_tSNE_producto.png"),ComidaTSNEventa:e("comida_rapida_III_tSNE_venta.png"),ComidaSOMdia:e("comida_rapida_III_SOM_dia.png"),ComidaSOMprod:e("comida_rapida_III_SOM_producto.png"),ComidaSOMventa:e("comida_rapida_III_SOM_venta.png"),ComidaDist:e("comida_rapida_II_dist.png"),ComidaRegL:e("comida_rapida_II_reglineal.png"),ComidaKNN:e("comida_rapida_II_knn.png"),ComidaSVM:e("comida_rapida_II_svm.png"),ComidaRF:e("comida_rapida_II_rf.png"),ComidaGB:e("comida_rapida_II_gb.png"),ComidaAnalisis:e("comida_rapida_I_analisis.png"),ComidaProd:e("comida_rapida_I_productos.png"),ComidaMonteCarlo:e("comida_rapida_I_montecarlo.png"),INGVHiper:e("resultados_hiperparametros.png"),INGVPred:e("predicion_real.png"),INGVError:e("error_prediccion.png"),K2020Req:e("respuesta_pais.png"),K2020RankC:e("ranking_paises_respuestas.png"),K2020ReqAge:e("respuestas_edad_region.png"),K2020ComR:e("sueldo_region.png"),K2020ComA:e("sueldo_edad.png"),GLifeExample:e("patron_juego_vida.gif"),GLifeStartStop:e("comp_start_stop.png"),GLifePred:e("comp_prediccion.png"),SomGral:e("som.png"),SomMNIST:e("mnist.png"),SomDistNum:e("dist_clase_x_neurona_numeros.png"),SomMatrixNum:e("matriz_confusion_class_numeros.png"),SomFace:e("face_expression.png"),SomDistFace:e("dist_clase_x_neurona_rostros.png"),SomMatrixFace:e("matriz_confusion_class_rostros.png"),FIFA19Age:e("Age-1.png"),FIFA19Club:e("Club-1.png"),FIFA19AgeGan:e("EdadHabGan-1.png"),FIFA19Money:e("MoneyIV-2.png"),FIFA19Pred:e("PredGraph-1.png")},p="A Vercel-like developer portfolio website template made with Typescript and SvelteKit.",u=`<div style="display: flex; justify-content: center; text-align: center;">
    <img width="50%" height="auto" src='https://upload.wikimedia.org/wikipedia/commons/e/e4/Twitter_2012_logo.svg'>
</div>

Twitter es actualmente una dinámica fuente de contenidos que, dada su popularidad e impacto, se ha convertido en uno de los principales medios de difusión de los principales medios de comunicación tradicionales (radio y televisión).

<br><br>
El análisis de sentimientos considera los tweets de distintos noticieros chilenos durante el periodo de abril a junio ed 2019 e intenta encontrar algún patrón entre los sentimientos evocados por los tweets de los noticieros. Para ello, se analizan las publicaciones que han hecho en Twitter los noticieros de @CNNChile, @ahoranoticiasAN, @24HorasTVN, @T13 y @CHVNoticias.

<br><br>
La mayor cantidad de tweets se realizaron en junio por las cuentas, aunque @CNNChile y @CHVNoticias presentan varios tweets los meses anterioes, tal como se mestra en la distribución:

<div style="display: flex; justify-content: center; text-align: center; margin-top: 2em;">
    <img width="70%" height="auto" src='https://raw.githubusercontent.com/desareca/Analisis-Sentimientos-Noticieros/master/Distribucion%20tweets%20tiempo.png'>
</div>

<br><br>
Una vez realizado el análisis observamos que las emociones predominantes en los tweets son confianza, miedo y anticipación. Además, en menor medida existen tweets con emoción de alegría. Los tweets presentan un bajo nivel de sorpresa, tristeza, ira y aversión, tal como se muestra en la siguiente distribución temporal: 

<div style="display: flex; justify-content: center; text-align: center; margin-top: 2em;">
    <img width="70%" height="auto" src='https://raw.githubusercontent.com/desareca/Analisis-Sentimientos-Noticieros/master/Analisis%20sentimientos%20tweets%20tiempo.png'>
</div>

<br><br>
Para mayor detalle revisar los enlaces.
`,g=`<div style="display: flex; justify-content: center; text-align: center;">
<img width="70%" height="auto" src='https://images.pexels.com/photos/54581/escalator-stairs-metal-segments-architecture-54581.jpeg'>
</div>
<br><br>
El objetivo del análsis es predecir el puntaje de los clientes en un mall considerando indicadores de cada consumidor. El dataset contiene la siguiente información:
<ul>
    <li>CustomerID: Identificador único para cada cliente.</li>
    <li>Gender: Género de cada cliente (Másculino/Femenino).</li>
    <li>Age: Edad del cliente.</li>
    <li>Annual Income (k$): Ingresos anuales del cliente.</li>
    <li>Spending Score (1-100): Puntaje asignado por el centro comercial en función del comportamiento y gasto del cliente.</li>
</ul>
<br>

El siguiente análisis considera:<br>
<ul>
    <li>Un breve análisis exploratorio de los datos.</li>
    <li>Dividir los datos en conjunto de entrenamiento y validación (80%-20%).</li>
    <li>Con esto se realizarán diversos algoritmos de regresión mediante ternsorflow, donde el entrenamiento se realizará utilizando validación cruzada aleatoria (en cada algoritmo hay una descripción del procedimiento utilizado).</li>
    <li>El conjunto de validación se utilizará para comparar el RMSE de cada método.</li>
</ul>
<br>
Los resultados (ver figura más abajo) indican que los algortimos con mejor desempeño son KNN y Red Neuronal. Esto se debe a que la relación entre los datos es no-lineal. El mejor resultado lo entrega KNN, pero tiene la desventaja que depende de los datos selecionados y no es mejorable, ya que toma el promedio de los datos con menores distancias. Por otro lado la red neuronal, aunque presenta un resultado levemente peor, se puede mejorar optimizando los hiperparámetros (learning_rate y configuración de la red).

<table style="border:1px; width: auto; margin: 2em auto 0 auto; padding: 20px">
  <colgroup>
    <col style="width: 15%;">
    <col style="width: 75%;">
    <col style="width: 10%;">
  </colgroup>
  <tr>
    <td style='text-align: right; width: 10%'>Regresión Lineal</td>
    <td>
        <div style="display: flex; justify-content: center; text-align: center; margin: 1em 0;">
            <img width="90%" height="auto" src='https://github.com/desareca/Proyectos_tensorflow/raw/master/Analisis-Consmidores/loss_elasticnet.png'>
        </div>
    </td>
    <td>RMSE: 23.94</td>
  </tr>
  <tr>
    <td style='text-align: right'>SVM-Lineal</td>
    <td>
        <div style="display: flex; justify-content: center; text-align: center; margin: 1em 0;">
            <img width="90%" height="auto" src='https://github.com/desareca/Proyectos_tensorflow/raw/master/Analisis-Consmidores/loss_svm_lineal.png'>
        </div>
    </td>
    <td>RMSE: 24.77</td>
  </tr>
  <tr>
    <td style='text-align: right'>KNN (k=7)</td>
    <td>
        <div style="display: flex; justify-content: center; text-align: center; margin: 1em 0;">
            <img width="90%" height="auto" src='https://github.com/desareca/Proyectos_tensorflow/raw/master/Analisis-Consmidores/loss_red_neuronal.png'>
        </div>
    </td>
    <td>RMSE: 20.91</td>
  </tr>
  <tr>
    <td style='text-align: right'>Red Neuronal</td>
    <td>
        <div style="display: flex; justify-content: center; text-align: center; margin: 1em 0;">
            <img width="90%" height="auto" src='https://github.com/desareca/Proyectos_tensorflow/raw/master/Analisis-Consmidores/loss_elasticnet.png'>
        </div>
    </td>
    <td>RMSE: 20.91</td>
  </tr>
</table>

El desarrollo y código codigo asociado se encuantra en:

`,b=`<div style="display: flex; justify-content: center; text-align: center;">
<img width="70%" height="auto" src='https://images.pexels.com/photos/1093161/pexels-photo-1093161.jpeg?auto=compress&cs=tinysrgb&w=1260&h=750&dpr=2'>
</div>
<br><br>
Clasificación binaria para predecir en base a las variables si un paciente con un determinado número de medidas médicas es susceptible de tener enfermedad de corazón o no.
<br><br>
Para entrenar los modelos de clasifición se considera lo siguiente:
<ul>
    <li>La clasificación se considerará satisfactoria si alcanza una exactitud de 0.9.</li>
    <li>Para ello se realizará un análisis exploratorio de las variables evaluando que variables aportan a la predicción, posteriormente se dividirán los datos en conjunto de entrenamiento (80%) y conjunto de validación (20%).</li>
    <li>Con esto se realizarán diversos algoritmos de clasificación binaria mediante ternsorflow, donde el entrenamiento se realizará utilizando validación cruzada aleatoria (en cada algoritmo hay una descripción del procedimiento utilizado).</li><li>Finalmente la comparación de los algoritmos se relizará con la exactitud de cada algoritmo sobre el conjunto de validación.</li>
</ul>
<br>
Al explorar los datos se observa que no existe una relación lineal clara entre las features y el target de acuerdo con la matriz de correlación. Esto indica que un modelo no lineal podría funcionar mejor.
<div style="display: flex; justify-content: center; text-align: center; margin: 2em;">
    <img width="60%" height="auto" src='https://github.com/desareca/Proyectos_tensorflow/raw/master/Probabilidad-Infarto-Cardiaco/corr.png'>
</div>

Al entrenar y validar los modelos nos encontramos con que eL algoritmo que presenta el mejor desempeño es el SVM Radial con una exactitud de 0.98, muy por sobre el resto.

<div style="display: flex; justify-content: center; text-align: center; margin: 2em;">
    <img width="50%" height="auto" src='https://github.com/desareca/Proyectos_tensorflow/raw/master/Probabilidad-Infarto-Cardiaco/acc.png'>
</div>

El detalle de la exploración de datos y desarrollo de los modelos se encuentar en:`,h=`<div style="display: flex; justify-content: center; text-align: center;">
<img width="70%" height="auto" src='https://images.pexels.com/photos/1884574/pexels-photo-1884574.jpeg?auto=compress&cs=tinysrgb&w=640&h=427&dpr=2'>
</div>
<br><br>
El objetivo de este análisis es prededir la remuneración de futbolistas a partir de estadísticas sobre sus habilidades de juego. Para ellos se filtrarán los datos de habilidades y se realizará un análisis exploratorio para identificar patrones en los datos que permitan tener información fiable e implementar una predicción mediante una regresión lineal en tensorflow.
<br><br>
El análisis muestra que los datos presentan correlación alta en varias variables, por un lado esto puede presentar una complicación a la hora de entrenar un modelo. Por otro lado podría indicar que grupos de jugadores tienen habilidades en común, lo que es coherente con los conjuntos de habilidades que deben poseer las distintas posiciones dentro del campo.
<div style="display: flex; justify-content: center; text-align: center; margin: 2em;">
    <img width="100%" height="auto" src='https://github.com/desareca/Proyectos_tensorflow/raw/master/Remuneracion-Furtbolistas/corr.png'>
</div>

El modelo resultante entrega un RMSE promedio de 4663, que representa un 25% aproximadamente del rango máximo de los datos. Algunos ejemplos de predicción:


<table style="border:1px; width: auto; margin: 2em auto 2em auto; padding: 20px"><thead>
  <colgroup>
    <col style="width: 50%;">
    <col style="width: 25%;">
    <col style="width: 25%;">
  </colgroup>
  <tr>
    <th style="text-align: left">Name</th>
    <th>Wage</th>
    <th>Prediccion</th>
  </tr></thead>
<tbody>
  <tr>
    <td>Park Hyeong Jin</td>
    <td style="text-align: center">2000.0</td>
    <td style="text-align: center">4815.0</td>
  </tr>
  <tr>
    <td>S. Grønning</td>
    <td style="text-align: center">1000.0</td>
    <td style="text-align: center">235.0</td>
  </tr>
  <tr>
    <td>D. Diagné</td>
    <td style="text-align: center">3000.0</td>
    <td style="text-align: center">5660.0</td>
  </tr>
  <tr>
    <td>S. Janssen</td>
    <td style="text-align: center">1000.0</td>
    <td style="text-align: center">3993.0</td>
  </tr>
  <tr>
    <td>C. Wondolowski</td>
    <td style="text-align: center">4000.0</td>
    <td style="text-align: center">5159.0</td>
  </tr>
  <tr>
    <td>E. Castillo</td>
    <td style="text-align: center">6000.0</td>
    <td style="text-align: center">3207.0</td>
  </tr>
  <tr>
    <td>Ding Haifeng</td>
    <td style="text-align: center">4000.0</td>
    <td style="text-align: center">6210.0</td>
  </tr>
  <tr>
    <td>David Haro</td>
    <td style="text-align: center">2000.0</td>
    <td style="text-align: center">1540.0</td>
  </tr>
  <tr>
    <td>Escudero</td>
    <td style="text-align: center">20000.0</td>
    <td style="text-align: center">45746.0</td>
  </tr>
  <tr>
    <td>R. Morioka</td>
    <td style="text-align: center">16000.0</td>
    <td style="text-align: center">7435.0</td>
  </tr>
</tbody></table>

El detalle de la exploración de datos y desarrollo del modelo se encuentar en:`,y=`<div style="display: flex; justify-content: center; text-align: center;">
<img width="70%" height="auto" src='https://cdn.resfu.com/media/img_news/montaje-de-las-portadas-de-fifa-19-de-ilustrador-fred-illustrations--montaje-fred-illustrations.png?size=1000x&lossy=1&ext=jpeg'>
</div>
<br><br>
FIFA 19 (de la saga FIFA) es un videojuego de simulación de fútbol desarrollado por EA Vancouver como parte de la serie FIFA de Electronic Arts.
<br><br>
El primer juego de la saga se caracterizaba por su perspectiva isométrica o de tres cuartos, que se diferenciaba de los otros títulos que ofrecían una vista desde arriba o vista de pájaro. Un aspecto importante era el sonido del público en el estadio, que estaba basado en grabaciones en vivo y que le proporcionaban un mayor realismo al desarrollo del juego con cánticos de los aficionados. El juego presentaba representativos nacionales, y un equipo especial formado por un selectivo de jugadores, este equipo se llama EA Sports.
<br><br>
A pesar de todos los defectos que presentaba no hay duda que en su época fue todo un éxito, la gente de EA Sports año tras año continuaba mejorando sus juegos FIFA. La nueva generación de FIFA cambio mucho, la inteligencia artificial (IA) de los jugadores es ahora más desarrollada.
<br><br>
Al revisar los datos, no encontramos con que la mayoría de jugadores tienen entre 20 y 30 años. con una cola hacia la derecha que llega hasta casi los 40 años.
<div style="display: flex; justify-content: center; text-align: center; margin: 2em;">
    <img width="60%" height="80%" src=\${AssetsImage.FIFA19Age}>
</div>
Por otro lado la mayoría de los equipos tienen en torno a 25 jugadores y además la distribució de jugadores por club parece ser normal.<div style="display: flex; justify-content: center; text-align: center; margin: 2em;">
    <img width="60%" height="80%" src=\${AssetsImage.FIFA19Club}>
</div>
Algo peculiar es que aunque los jugadores tienen su punto máximo en valor de contrato en torno a lo 27 años y después comienza a baja, no sucede de la misma forma con la remuneración donde punto máximo es en torno a los 30 años y baja más lentamente.
<div style="display: flex; justify-content: center; text-align: center; margin: 2em;">
    <img width="60%" height="80%" src=\${AssetsImage.FIFA19AgeGan}>
</div>
También existe una clara relación entre reputación del jugador y su remuneración, tal como se observa en la imagen. Aunque existen ciertas excepciones, tal como es el caso de Z. Ibrahimovic, que tiene reputación 5 y su valor es de 14M€, esto se puede deber a su edad (tiene 36 años), su estado físico y/o al equipo en que juega.
<div style="display: flex; justify-content: center; text-align: center; margin: 2em;">
    <img width="60%" height="80%" src=\${AssetsImage.FIFA19Money}>
</div>
Para hacer la predicción se utiliza la función h2o.automl de la librería h2o. H2O AutoML es una plataforma de inteligencia artificial que automatiza el proceso de creación, selección y optimización de un gran número de modelos de aprendizaje automático mediante el metodo de Stacked Ensembles.
<br><br>
En esta predicción no se consideran las variables Wage ni Release.Clause. Los datos se dividen en conjunto de entrenamiento y test (70% y 30%). Se utiliza validación cruzada con 10 folds, y la métrica a optimizar es el RMSLE.
<br><br>
La comparación entre predicción y valor real muestra un muy buen resultado, logrando resultados muy cercanos al real. Para remuneraciones muy altas el error aumenta, esto se puede deber a que hay pocos jugadores con remuneraciones muy altas y el elgoritmo tiene poca información de estos durante su entrenamiento.
<div style="display: flex; justify-content: center; text-align: center; margin: 2em;">
    <img width="60%" height="80%" src=\${AssetsImage.FIFA19Pred}>
</div>
El detalle de la exploración de datos y desarrollo del modelo se encuentar en:`,v=`<div style="display: flex; justify-content: center; text-align: center;">
<img width="70%" height="auto" src='https://www.mdpi.com/cleantechnol/cleantechnol-02-00011/article_deploy/html/images/cleantechnol-02-00011-g001.png'>
</div>
<br><br>			
Los mapas autorganizados de Kohonen son un algoritmo que a partir de un proceso iterativo de comparacion con un conjunto de datos y cambios para aproximarse a los mismos, crea un modelo de esos mismos datos que puede servir para agruparlos por criterios de similitud; adicionalmente, este agrupamiento se produce de forma que la proyeccion de estos datos sobre el mapa distribuya sus caracteristicas de una forma gradual. El Mapa de Kohonen, SOM se usa para diferentes aplicaciones:
<ul>			
<li>Clustering: se pueden agrupar datos del conjunto de entrada, atendiendo a diferentes criterios.
<li>Visualizacion: este agrupamiento, como se realiza de una forma ordenada, permite visualizar al conjunto de entrada y descubrir caracteristicas nuevas o relaciones que no se habian previsto de antemano. Tambien permite visualizar la evolucion temporal de un conjunto de datos: proyectando un vector en etapas sucesivas sobre un mapa entrenado se ve como se va moviendo de una zona con unas caracteristicas determinadas a otra.
<li>Clasificacion: aunque el entrenamiento del mapa no tiene en cuenta la etiqueta de clase o el tipo de cada uno de los vectores de entrada, una vez terminado el entrenamiento se puede asignar algun tipo de etiqueta a cada nodo, y se puede usar para clasificar datos desconocidos.
<li>Interpolacion de una funcion: asignando valores numericos a cada uno de los nodos de la red de Kohonen, se pueden asignar esos valores numericos a los vectores de entrada: a cada vector (dato) de entrada le correspondera el numero o vector asignados a la salida mas cercana.
<li>Cuantizacion vectorial: corresponde a la aplicacion de una entrada continua a una salida que esta discretizada, obteniendo a partir de un vector cualquiera el vector mas cercano de un conjunto previamente establecido.
</ul>
A continuacion se implementan mapas autorganizados para la reduccion dimensional, visualizacion de caracteristicas y clasificacion de imágenes, considerando dataset de números y de rostros.

<h2>dataset MNIST</h2>
MNIST (Instituto Nacional Modificado de Estandares y Tecnologia) es el conjunto de datos de facto de vision mundial de la vision de computadora. Desde su lanzamiento en 1999, este clasico conjunto de dato de imagenes manuscritas ha servido como base para los algoritmos de clasificacion de referencia. A medida que surgen nuevas tecnicas de aprendizaje automatico, MNIST sigue siendo un recurso confiable para investigadores y estudiantes por igual.
<br><br>			
El conjunto de datos mixto de Instituto Nacional de estandares y tecnologia (MNIST) es una coleccion de 70.000 imagenes de digitos escritos a mano. Los datos fue creados para actuar como un referente para los algoritmos de reconocimiento de imagen.
<br><br>
<div style="display: flex; justify-content: center; text-align: center;">
    <img width="70%" height="auto" src=\${AssetsImage.SomMNIST}>
</div>
<br><br>
Al entrenar un SOM con los datos del MNIST la información de cada tipo de número se ubica en zonas relativamente diferentes del resto de los demás números, esto indica que el modelo separa las caracteristicas que diferencian a cada clase.
<br><br>
<div style="display: flex; justify-content: center; text-align: center;">
    <img width="70%" height="auto" src=\${AssetsImage.SomDistNum}>
</div>
<br><br>
Utilizando la representación de los números en el SOM tenemos una clasificación con un accuraccy de 84.9%. Como se observa en la matriz de confusión, los numeros 4 y 7 con el núemro 9 presentan algunos problemas, asi como el 3 y el 8 con el numero 5.
<br><br>
<div style="display: flex; justify-content: center; text-align: center;">
    <img width="50%" height="auto" src=\${AssetsImage.SomMatrixNum}>
</div>
<br><br>
<h2>Face Expression</h2>
Base de datos del <strong>Advanced Multimedia Processing (AMP) Lab</strong> de la <strong>Cornell University</strong>, consta de 13 sujetos con 75 imágenes cada sujeto, de 64x64 píxeles en escala de grises, que muestran diferentes expresiones faciales. Estas imágenes faciales se recopilaron bajo la misma condicion de iluminación utilizando una camara CCD. Las imágenes de los rostros fueron registradas por la ubicación de los ojos.
<br><br>
<div style="display: flex; justify-content: center; text-align: center;">
    <img width="70%" height="auto" src=\${AssetsImage.SomFace}>
</div>
<br><br>
El SOM resultante de los datos de la base de datos Face Expression genera que cada rostrose ubique en zonas relativamente diferentes del resto.
<br><br>
<div style="display: flex; justify-content: center; text-align: center;">
    <img width="70%" height="auto" src=\${AssetsImage.SomDistFace}>
</div>
<br><br>
Utilizando la representación de los rostros en el SOM tenemos una clasificación con un accuraccy de 97.5%. Este resultado es muy bueno y reconoce a cada sujeto en su mayoría.
<br><br>
<div style="display: flex; justify-content: center; text-align: center;">
    <img width="50%" height="auto" src=\${AssetsImage.SomMatrixFace}>
</div>
<br><br>
Para revisar con más profundidad el análisis ir a los enlaces.`,f=`El Juego de la vida es un autómata celular diseñado por el matemático británico John Horton Conway en 1970. Es un juego de cero jugadores, en el que su evolución es determinada por un estado inicial, sin requerir intervención adicional.
<br><br>
<div style="display: flex; justify-content: center; text-align: center;">
<img width="50%" height="auto" src='https://miro.medium.com/v2/resize:fit:720/format:webp/1*6wS-kXlOCBsAJciygkJtDA.gif'>
</div>
<br><br>	
El juego se desarrolla en una cuadrícula de celdas, donde cada celda puede estar viva o muerta. En cada paso del tiempo, el estado de cada celda se determina por el estado de sus ocho vecinos (celdas adyacentes). Las reglas son las siguientes:
<ul>
<li>Una celda viva con menos de dos vecinos vivos muere (subpoblación).
<li>Una celda viva con dos o tres vecinos vivos permanece viva (supervivencia).
<li>Una celda viva con más de tres vecinos vivos muere (sobrepoblación).
<li>Una celda muerta con exactamente tres vecinos vivos se convierte en una celda viva (reproducción). 
</ul>
<br>
A continuación se implementa una solución utilizando algoritmos genéticos para encontrar el punto de partida edl juego a partir de estados finales.`,C=`<div style="display: flex; justify-content: center; text-align: center;">
<img width="70%" height="auto" src=\${AssetsImage.K2020Req}>
</div>
<br><br>
El año 2020 Kaggle realizó una encuesta a nivel de toda la industria que presenta una visión verdaderamente completa del estado de la ciencia de datos y el aprendizaje automático. La encuesta estuvo activa durante 3,5 semanas en octubre y, tras depurar los datos se obtuvieron 20.036 respuestas.
<br><br>
Los resultados incluyen cifras sin procesar sobre quién trabaja con datos, qué está sucediendo con el aprendizaje automático en diferentes industrias y las mejores maneras para que los nuevos científicos de datos se adentren en este campo. 
<br><br>
A continuación se presenta un análisis con visualización interactiva de los datos.`,x=`<div style="display: flex; justify-content: center; text-align: center;">
<img width="70%" height="auto" src="https://images.pexels.com/photos/13337517/pexels-photo-13337517.jpeg?auto=compress&cs=tinysrgb&w=1260&h=750&dpr=2">
</div>
<br><br>
El Instituto Nacional de Geofísica y Vulcanología (INGV) de Italia se centra en la geofísica y la vulcanología. Su principal objetivo es contribuir a la comprensión del sistema terrestre y, al mismo tiempo, mitigar los riesgos asociados. Encargado de monitorear la sismicidad y la actividad volcánica activa las 24 horas del día en todo el país, el INGV busca encontrar los precursores detectables más tempranos que proporcionen información sobre la cronología de futuras erupciones volcánicas.
<br><br>
El objetivo es predecir cuándo ocurrirá la próxima erupción de un volcán, para ello se analiza un amplio conjunto de datos geofísicos recopilados por sensores instalados en volcanes activos, calculando features de las series temporales para entrenar un modelo XGBoost que prediga cuando será la próxima erupción.`,I=`<h1>Análisis Exploratorio e Inferencia para determinar estacionalidad en las ventas.</h1>
<br><br>
<div style="display: flex; justify-content: center; text-align: center;">
<img width="70%" height="auto" src=\${AssetsImage.ComidaAnalisis}>
</div>
<br><br>
Como parte del Diplomado en Data Science desarrollé un conjunto de notebooks para aplicar distintas herramientas de Data Science en un contexto real y acotado.<br><br>
Para el desarrollo de este y demás notebooks se consideran los datos reales de venta de un local de comida rápida. En este caso, tenemos el archivo Ventas 2021-2022.xlsx, que contiene las ventas diarias del 2021/2022 del local. Cada fila representa la venta diaria de un producto.<br><br>
El objetivo principal es realizar una estimación de venta (2 semanas) de los principales productos del local para poder planificar la compra de suministros mediante una simulación Monte Carlo y así ningún cliente quede sin comer 🤤🍔🍟.
Además, se realiza un análisis exploratorio utilizando la librería SweetViz que entrega de manera automática las principales estadísticas y visualizaciones de un análsiis exploratorio típico y un test de hipótesis sobre como varía la estacionalidad de la venta de cada producto, con el fin de priorizar el stock de los productos.
<br><br>
<strong>Consideraciones</strong><br><br>
Para el análisis sólo se consideran los productos más relevantes en ventas y/o que están actualmente en carta, estos son:
<ul>
<li>Papas Fritas</li>
<li>Churrascos</li>
<li>Café</li>
<li>Chuleta de Cerdo</li>
<li>1/4 de Pollo</li>
<li>Carne Mechada</li>
<li>Barros Luco</li>
<li>Chacarero</li>
<li>Completo</li>
<li>SalchiPapas</li>
</ul><br>
Además, sólo se consideran los meses de Diciembre, Enero y Febrero, debido a que este tipo de negocio es mayormente estacional y la simulación podría no ser necesariamente válida considerando un año completo.`,A=`<h1>Predicción de Ventas utilizando algoritmos de Machine Learning.</h1>
<br><br>
<div style="display: flex; justify-content: center; text-align: center;">
<img width="70%" height="auto" src="https://tecnologiabi.com/wp-content/uploads/2023/06/pronosticos-de-ventas-con-machine-learning.jpg">
</div>
<br><br>
Continuando con la serie de notebooks, tenemos datos de venta en un local de comida rápida en funcionamiento actualmente, que corresponden a los años 2020, 2021 y 2022.<br><br>
Estos datos tienen información de ventas diarias de Papas Fritas, Churrascos, Carne Mechada, Completo, SalchiPapas (ya me dió hambre 😋)....<br><br>
El objetivo es realizar una predicción de ventas de la semana siguiente si se cuentan con los datos de ventas de la semana anterior. Con esto se puede evaluar precios y planificar suministros, así ningún cliente se queda sin comer 🤤🍔🍟 y ganamos 💲💲💲.
<br><br>
<strong>Consideraciones</strong><br>
Se realiza un limpieza y análisis exploratorio que permita extraer información relevante de los datos.
\\nAdemás, se implementan 5 modelos (Regresión Lineal, KNN, SVM, Random Forest y Gradient Boosting) y se evalua el mejor desempeño de acuerdo con distintas métricas.\\nPor simplicidad se consideran las ventas totales de cada día de la semana anterior y la fecha de la semana a predecir.\\nLos datos tienen varias semanas sin datos debido a la pandemia, por lo que se consideran solo las semanas con datos.`,_=`<h1>Busqueda de Patrones utilizando herramientas de aprendizaje no supervisado.</h1>
A continuación se presentan 2 aplicaciones, la primera desarrollando una función que permita implementar mapas autoorganizados (SOM) en Python y aplicarlo al dataset iris.<br><br>
Para luego realizar un análisis sobre los datos de ventas del local de comida rápida utilizando distintas herramnientas de análisis no supervisado, con el fin de buscar relaciones entre ventas, productos y días. Los algoritmos utilizados son PCA, ISOMAP, t-SNE y SOM.
<br><br>
<h2>Self-Organizing Map (SOM)</h2>
<div style="display: flex; justify-content: center; text-align: center;">
<img width="70%" height="auto" src=\${AssetsImage.ComidaSOM}>
</div>
<br><br>
Un mapa autoorganizado (self-organizing map, SOM) o un mapa autoorganizado de características (self-organizing feature map, SOFM) es un tipo de red neuronal, que es entrenada usando aprendizaje no supervisado para producir una representación discreta del espacio de las muestras de entrada, llamado mapa.<br><br>
Los SOMs son útiles para visualizar vistas de baja dimensión de datos de alta dimensión, semejante a un escalado multidimensional. El objetivo del aprendizaje en los mapas autoorganizados es provocar que diferentes partes de la red respondan similarmente a ciertos patrones de la entrada.`,w=`<h1>Busqueda de Patrones utilizando herramientas de deep learning.</h1>
Este análisis considera 2 partes, primero la implementación de un <strong>Autoencoder variacional</strong>, el objetivo es revisar el funcionamiento del algoritmo y generar datos sintéticos en caso de ser necesario. Luego una predicción de ventas de un local de comida rápida utilizando varios algoritmos de <strong>machine learnig</strong> y <strong>deep learning</strong>.

<h2>Autoencoders Variacionales (VAE)</h2>
Un <strong>AutoEncoder (AE)</strong> es un tipo de red neuronal que se utiliza para aprender codificaciones eficientes de datos no etiquetados ( aprendizaje no supervisado ), normalmente se utiliza para reducción de la dimensionalidad. 
<br><br>

Los <strong>Variational AutoEncoders (VAE)</strong> son modelos una combinación de <strong>AE´s</strong> con distribuciones de probabilidad. Su principal uso es el de construir modelos generativos que son capaces de producir datos sintéticos que siguen los mismos patrones que los grandes conjuntos de datos de los que se alimentan. Normalmente, se han usado para generar imágenes que asemejan, por ejemplo, características conocidas tales como caras, vehículos, habitáculos, etc. aunque en teoría podrían usarse para la generación de cualquier tipo de dato.

<br><br>
<h6>Ejemplo de VAE</h6>
    <div style="display: flex; justify-content: center; text-align: center;">
        <img width="70%" height="auto" src=\${AssetsImage.ComidaDLVae}>
    </div>
<br><br>

<h2>Predicción de Ventas con Deep Learning.</h2>
Se aplicaron 4 modelos Obteniendo los siguientes resultados:
<ul>
    <li>Regresión Lineal (línea base)</li>
        <div style="display: flex; justify-content: center; text-align: center;">
            <img width="90%" height="auto" src=\${AssetsImage.ComidaDLReg}>
        </div>
    <li>Random Forest (mejor modelo del caso de uso de aprendizaje supervisado)</li>
        <div style="display: flex; justify-content: center; text-align: center;">
            <img width="90%" height="auto" src=\${AssetsImage.ComidaDLRF}>
        </div>
    <li>Depp Learning:</li>
    <ul>
        <li>Red de una capa densa.</li>
            <div style="display: flex; justify-content: center; text-align: center;">
                <img width="90%" height="auto" src=\${AssetsImage.ComidaDLDLRes}>
            </div>
        <li>Red con 3 capas convolucionales en paralelo / una capa densa.</li>
            <div style="display: flex; justify-content: center; text-align: center;">
                <img width="90%" height="auto" src=\${AssetsImage.ComidaDLCNNRes}>
            </div>
        <li>Red con 3 capas convolucionales en paralelo / una capa densa, entrenada a partir de datos sintéticos generados con un <strong>VAE</strong>.</li>
            <div style="display: flex; justify-content: center; text-align: center;">
                <img width="90%" height="auto" src=\${AssetsImage.ComidaDLCNNVaeRes}>
            </div>
    </ul>
</ul>`;function s(t,d,l=a){return d.forEach(r=>{const c=new RegExp(`\\$\\{AssetsImage\\.${r}\\}`,"g");t=t.replace(c,l[r])}),t}const i={ComidaIV:s(w,["ComidaDLVae","ComidaDLReg","ComidaDLRF","ComidaDLDLArq","ComidaDLDLRes","ComidaDLCNNArq","ComidaDLCNNRes","ComidaDLCNNVaeRes","ComidaDLCNNPred"]),ComidaIII:s(_,["ComidaSOM"]),ComidaII:A,ComidaI:s(I,["ComidaAnalisis"]),Volcanic:x,Kaggle2020:s(C,["K2020Req"]),GameLife:f,SomClassify:s(v,["SomGral","SomMNIST","SomDistNum","SomMatrixNum","SomFace","SomDistFace","SomMatrixFace"]),Fifa19:s(y,["FIFA19Age","FIFA19Club","FIFA19AgeGan","FIFA19Money","FIFA19Pred"]),RemFut:h,InfCardiaco:b,ConsumMall:g,NoticiaChile:u,PortfolioSvelte:p},S=[{slug:"venta-comida-rapida-4",color:"steelblue",description:i.ComidaIV,shortDescription:"Busqueda de Patrones utilizando herramientas de deep learning",links:[{to:"https://colab.research.google.com/drive/12WJaWLLVgmc-jrzu4ibFcjx3C_i0d_hy#scrollTo=G6XKIhQSV6Ms",label:"Colab"}],logo:n.Python,name:"Ventas Local de Comida Rápida (Parte IV)",period:{from:new Date(2022,1,5),to:new Date(2022,4,30)},skills:o("python","pandas","numpy","matplotlib","seaborn","sklearn","keras","tensorflow"),type:"Machine Learning",screenshots:[{label:"Distribución de Variables",src:a.ComidaDist},{label:"Representación de los datos con PCA agrupado por días",src:a.ComidaPCAdia},{label:"Representación de los datos con PCA agrupado por productos",src:a.ComidaPCAprod},{label:"Representación de los datos con PCA agrupado por ventas",src:a.ComidaPCAventa},{label:"Representación de los datos con ISOMAP agrupado por días",src:a.ComidaISOMAPdia},{label:"Representación de los datos con ISOMAP agrupado por productos",src:a.ComidaISOMAPprod},{label:"Representación de los datos con ISOMAP agrupado por ventas",src:a.ComidaISOMAPventa},{label:"Representación de los datos con t-SNE agrupado por días",src:a.ComidaTSNEdia},{label:"Representación de los datos con t-SNE agrupado por productos",src:a.ComidaTSNEprod},{label:"Representación de los datos con t-SNE agrupado por ventas",src:a.ComidaTSNEventa},{label:"Representación de los datos con SOM agrupado por días",src:a.ComidaSOMdia},{label:"Representación de los datos con SOM agrupado por productos",src:a.ComidaSOMprod},{label:"Representación de los datos con SOM agrupado por ventas",src:a.ComidaSOMventa}]},{slug:"venta-comida-rapida-3",color:"steelblue",description:i.ComidaIII,shortDescription:"Busqueda de Patrones utilizando herramientas de aprendizaje no supervisado",links:[{to:"https://colab.research.google.com/drive/1jHPntGoAqJ3b6CeffmmgDpeHlv-NS0TQ#scrollTo=dTFGMi0MIXih",label:"Colab"}],logo:n.Python,name:`Ventas Local de Comida Rápida
Parte III`,period:{from:new Date(2022,1,5),to:new Date(2022,4,30)},skills:o("python","pandas","numpy","matplotlib","seaborn","sklearn"),type:"Machine Learning",screenshots:[{label:"Distribución de Variables",src:a.ComidaDist},{label:"Representación de los datos con PCA agrupado por días",src:a.ComidaPCAdia},{label:"Representación de los datos con PCA agrupado por productos",src:a.ComidaPCAprod},{label:"Representación de los datos con PCA agrupado por ventas",src:a.ComidaPCAventa},{label:"Representación de los datos con ISOMAP agrupado por días",src:a.ComidaISOMAPdia},{label:"Representación de los datos con ISOMAP agrupado por productos",src:a.ComidaISOMAPprod},{label:"Representación de los datos con ISOMAP agrupado por ventas",src:a.ComidaISOMAPventa},{label:"Representación de los datos con t-SNE agrupado por días",src:a.ComidaTSNEdia},{label:"Representación de los datos con t-SNE agrupado por productos",src:a.ComidaTSNEprod},{label:"Representación de los datos con t-SNE agrupado por ventas",src:a.ComidaTSNEventa},{label:"Representación de los datos con SOM agrupado por días",src:a.ComidaSOMdia},{label:"Representación de los datos con SOM agrupado por productos",src:a.ComidaSOMprod},{label:"Representación de los datos con SOM agrupado por ventas",src:a.ComidaSOMventa}]},{slug:"venta-comida-rapida-2",color:"steelblue",description:i.ComidaII,shortDescription:"Predicción de Ventas utilizando algoritmos de Machine Learning",links:[{to:"https://colab.research.google.com/drive/1hZTWo7pMp7SQ4lD3nCYMmZHfiXkb3TFB#scrollTo=A8NGJQD5uqn3",label:"Colab"}],logo:n.Python,name:`Ventas Local de Comida Rápida
Parte II`,period:{from:new Date(2022,1,5),to:new Date(2022,4,30)},skills:o("python","pandas","numpy","matplotlib","seaborn","sklearn"),type:"Machine Learning",screenshots:[{label:"Distribución de Variables",src:a.ComidaDist},{label:"Resultados Regresión Lineal",src:a.ComidaRegL},{label:"Resultados Regresión KNN",src:a.ComidaKNN},{label:"Resultados Regresión SVM",src:a.ComidaSVM},{label:"Resultados Regresión Random Forest",src:a.ComidaRF},{label:"Resultados Regresión Gradient Boosting",src:a.ComidaGB}]},{slug:"venta-comida-rapida-1",color:"steelblue",description:i.ComidaI,shortDescription:"Análisis Exploratorio e Inferencia para determinar estacionalidad en las ventas",links:[{to:"https://colab.research.google.com/drive/18JFP09N0xWcBOtIUZYPHgAdcuKqQk4yo#scrollTo=D1J1UYzNW67C",label:"Colab"}],logo:n.Python,name:`Ventas Local de Comida Rápida
Parte I`,period:{from:new Date(2022,1,5),to:new Date(2022,4,30)},skills:o("python","pandas","numpy","matplotlib"),type:"Análisis de Datos",screenshots:[{label:"Análisis Exploratorio General",src:a.ComidaAnalisis},{label:"Análisis Exploratorio por Producto",src:a.ComidaProd},{label:"Simulación Monte Carlo",src:a.ComidaMonteCarlo}]},{slug:"prediccion-erupcion-volcanica",color:"royalblue",description:i.Volcanic,shortDescription:"Predicción de erupciones volcánicas con XGBoost",links:[{to:"https://www.kaggle.com/competitions/predict-volcanic-eruptions-ingv-oe/overview",label:"Kaggle"}],logo:n.R,name:"INGV - Predicción de Erupción Volcánica",period:{from:new Date(2020,10,11),to:new Date(2021,0,5)},skills:o("r","tidyverse","ggplot2"),type:"Series de Tiempo",screenshots:[{label:"Error (MAE) de los Hiperparámetros",src:a.INGVHiper},{label:"Prediccón vs Real",src:a.INGVPred},{label:"Error (MAE) de Predicción",src:a.INGVError}]},{slug:"kaggle-survey-2020",color:"royalblue",description:i.Kaggle2020,shortDescription:"Visualización de datos de la encuesta Kaggle 2020 sobre ciencia de datos y aprendizaje automático.",links:[{to:"https://www.kaggle.com/code/desareca/kaggle-survey-2020-analisys-by-region",label:"Kaggle"}],logo:n.R,name:"Encuesta Kaggle 2020: Análisis por región",period:{from:new Date(2020,10,19),to:new Date(2021,0,5)},skills:o("r","tidyverse","ggplot2","plotly"),type:"Visualización de Datos",screenshots:[{label:"Cantidad de respuestas por país",src:a.K2020Req},{label:"Paises con mayor cantidad de respuestas",src:a.K2020RankC},{label:"Distribución de edades por región",src:a.K2020ReqAge},{label:"Distribución de sueldos por región",src:a.K2020ComR},{label:"Distribución de sueldos por edad",src:a.K2020ComA}]},{slug:"game-life-genetic-algorithm",color:"royalblue",description:i.GameLife,shortDescription:"Optimización mediante algoritmos genéticos para resolver el juego de la vida inverso.",links:[{to:"https://www.kaggle.com/code/desareca/game-of-life-genetic-algorithm-spanish",label:"Kaggle"}],logo:n.R,name:"Game of Life - Genetic Algorithm",period:{from:new Date(2020,9,3),to:new Date(2020,9,31)},skills:o("r","tidyverse","ggplot2"),type:"Optimización - Algoritmos Genéticos",screenshots:[{label:"Implementación del juego de la vida",src:a.GLifeExample},{label:"Comparación de estados iniciales y finales",src:a.GLifeStartStop},{label:"Comparación de predicciones y resultados",src:a.GLifePred}]},{slug:"som-clasificacion-imagenes",color:"royalblue",description:i.SomClassify,shortDescription:"Clasificación de imágenes mediante mapas autorganizados de Kohonen.",links:[{to:"https://rpubs.com/desareca/SOM_clasificacion_imagenes",label:"RPubs"}],logo:n.R,name:"SOM, visualización y clasificación de imágenes",period:{from:new Date(2019,9,1),to:new Date(2019,9,31)},skills:o("r","tidyverse","ggplot2"),type:"Análisis de Datos",screenshots:[{label:"Estructura general de un SOM",src:a.SomGral},{label:"Distribución de números por neurona",src:a.SomDistNum},{label:"Matriz de Confusión SOM números",src:a.SomMatrixNum},{label:"Distribución de rostros por neurona",src:a.SomDistFace},{label:"Matriz de Confusión SOM rostros",src:a.SomMatrixFace}]},{slug:"fifa19-analisis-prediccion",color:"royalblue",description:i.Fifa19,shortDescription:"FIFA 19 (de la saga FIFA) es un videojuego de simulación de fútbol desarrollado por EA Vancouver como parte de la serie FIFA de Electronic Arts.",links:[{to:"https://www.kaggle.com/code/desareca/fifa-19-analisis-de-caracteristicas-y-prediccion",label:"Kaggle"},{to:"https://rpubs.com/desareca/Analisis-estadisticas-FIFA19",label:"RPubs"}],logo:n.R,name:"FIFA 19 - Analisis de caracteristicas y predicción",period:{from:new Date(2019,9,1),to:new Date(2019,9,31)},skills:o("r","tidyverse","ggplot2","h2o"),type:"Análisis de Datos",screenshots:[]},{slug:"prediccion-remuneracion-futbolistas",color:"steelblue",description:i.RemFut,shortDescription:"Predicción de remuneraciones de futbolistas a partir de estadísticas sobre sus habilidades de juego.",links:[{to:"https://github.com/desareca/Proyectos_tensorflow/tree/master/Remuneracion-Furtbolistas",label:"Repositorio"},{to:"https://rpubs.com/desareca/Prediccion-Sueldos-Futbolistas",label:"RPubs"}],logo:n.Python,name:"Predicción de remuneración de futbolistas ",period:{from:new Date(2019,9,1),to:new Date(2019,9,31)},skills:o("python","pandas","numpy","matplotlib","seaborn","sklearn","tensorflow"),type:"Regresión",screenshots:[]},{slug:"clasificacion-infarto-cardiaco",color:"steelblue",description:i.InfCardiaco,shortDescription:"Clasificación binaria para predecir en base a las variables si un paciente con un determinado número de medidas médicas es susceptible de tener enfermedad de corazón o no.",links:[{to:"https://github.com/desareca/Proyectos_tensorflow/tree/master/Probabilidad-Infarto-Cardiaco",label:"Repositorio"},{to:"https://rpubs.com/desareca/Clasificacion-infarto-cardiaco",label:"RPubs"}],logo:n.Python,name:"Clasificación de infarto cardíaco",period:{from:new Date(2019,9,1),to:new Date(2019,9,31)},skills:o("python","pandas","numpy","matplotlib","sklearn","tensorflow"),type:"Clasificación",screenshots:[]},{slug:"analisis-consumidores-mall",color:"steelblue",description:i.ConsumMall,shortDescription:"Regresión para predecir el puntaje de los clientes en un mall.",links:[{to:"https://github.com/desareca/Proyectos_tensorflow/tree/master/Analisis-Consmidores",label:"Repositorio"},{to:"https://rpubs.com/desareca/Analisis_Consumidores",label:"RPubs"}],logo:n.Python,name:"Análisis de Consumidores de un Mall",period:{from:new Date(2019,9,1),to:new Date(2019,9,31)},skills:o("python","pandas","numpy","matplotlib","sklearn","tensorflow"),type:"Análisis de Datos",screenshots:[]},{slug:"analisis-sentimientos-noticieros-chilenos",color:"royalblue",description:i.NoticiaChile,shortDescription:"Twitter es actualmente una dinámica fuente de contenidos que, dada su popularidad e impacto, se ha convertido en uno de los principales medios de difusión de los principales medios de comunicación tradicionales (radio y televisión).",links:[{to:"https://github.com/desareca/Analisis-Sentimientos-Noticieros",label:"Repositorio"},{to:"https://rpubs.com/desareca/Analisis_Sentimientos_Noticieros",label:"RPubs"}],logo:n.R,name:"Análisis de Sentimientos Noticieros Chilenos",period:{from:new Date(2019,5,1),to:new Date(2019,5,31)},skills:o("r"),type:"Análisis de Datos",screenshots:[]},{slug:"slick-portfolio-svelte",color:"#ff3e00",description:i.PortfolioSvelte,shortDescription:"A Vercel-like developer portfolio website template made with Typescript and SvelteKit.",links:[{to:"https://github.com/RiadhAdrani/slick-portfolio-svelte",label:"GitHub"}],logo:n.Svelte,name:"Slick Portfolio",period:{from:new Date},skills:o("svelte","ts","tailwind","sass"),type:"Website Template",screenshots:[{label:"screen 1",src:"https://images.unsplash.com/photo-1587620962725-abab7fe55159?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxzZWFyY2h8Mnx8cHJvZ3JhbW1pbmd8ZW58MHx8MHx8fDA%3D&auto=format&fit=crop&w=500&q=60"},{label:"2",src:"https://images.unsplash.com/photo-1516116216624-53e697fedbea?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxzZWFyY2h8NXx8cHJvZ3JhbW1pbmd8ZW58MHx8MHx8fDA%3D&auto=format&fit=crop&w=500&q=60"},{label:"3",src:"https://images.unsplash.com/photo-1537432376769-00f5c2f4c8d2?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxzZWFyY2h8MTB8fHByb2dyYW1taW5nfGVufDB8fDB8fHww&auto=format&fit=crop&w=500&q=60"},{label:"4",src:"https://images.unsplash.com/photo-1542903660-eedba2cda473?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxzZWFyY2h8MTJ8fHByb2dyYW1taW5nfGVufDB8fDB8fHww&auto=format&fit=crop&w=500&q=60"},{label:"5",src:"https://images.unsplash.com/photo-1619410283995-43d9134e7656?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxzZWFyY2h8MTZ8fHByb2dyYW1taW5nfGVufDB8fDB8fHww&auto=format&fit=crop&w=500&q=60"},{label:"6",src:"https://images.unsplash.com/photo-1585079542156-2755d9c8a094?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxzZWFyY2h8MTd8fHByb2dyYW1taW5nfGVufDB8fDB8fHww&auto=format&fit=crop&w=500&q=60"}]}],j="Proyectos",z={title:j,items:S};export{z as P};
